{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Project 2\n",
    "\n",
    "## Outline\n",
    "1. Prerequisites\n",
    "2. Clone the GitHub Repository and Install Dependencies\n",
    "3. User Agent\n",
    "4. Tool-calling DB Agent using GPT-4o-mini\n",
    "5. Running Inference\n",
    "6. Viewing the Conversation Trajectories\n",
    "7. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()\n",
    "# Please enter your API key\n",
    "new_api_key = ''\n",
    "while len(new_api_key) == 0:\n",
    "    new_api_key = getpass.getpass(\"Please input your API key: \")\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the GitHub Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!rm -rf ai612_project_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloning the GitHub repository\n",
    "!git clone -q https://github.com/benchay1999/ai612_project_2.git\n",
    "%cd ai612_project_2\n",
    "\n",
    "# Installing dependencies\n",
    "! pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('.env'):\n",
    "    os.remove('.env')\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(f'OPENAI_API_KEY=\"{new_api_key}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User LLM\n",
    "This User LLM simulates the behavior of users who interact with text-to-SQL systems without SQL knowledge. Let's take a look at the system prompt of the User LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system prompt:\n",
      "You are a human user who wants to retrieve data from an EHR database by interacting with an SQL agent.\n",
      "User instruction: \n",
      "\n",
      "Instruction: Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.\n",
      "\n",
      "Rules:\n",
      "- Current time is 2100-12-31 23:59:00.\n",
      "- You don't know SQL at all and only have a rough idea of what information the database contains.\n",
      "- Explain your intent in plain language so that the SQL agent understands exactly what you need.\n",
      "- Generate one request at a time to simulate the user's message.\n",
      "- Do not be too wordy in your messages. Be concise and to the point.\n",
      "- Do not give away all the instruction at once. Only provide the information necessary to ask or respond to the SQL agent.\n",
      "- Do not hallucinate information that is not provided in the instructions.\n",
      "- Do not repeat the exact instruction in the conversation. Instead, use your own words to convey the same information.\n",
      "- Even if the SQL agent transfers the task to you, you must not complete it yourself. You are reactive to the SQL agent and only respond to its clarifying questions.\n",
      "- If your goal is satisfied, generate '###END###' to end the conversation.\n",
      "- Try to make the conversation as natural as possible, and stick to the user instruction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.envs.user import LLMUser\n",
    "# dummy user agent\n",
    "user_agent = LLMUser(model=\"gpt-4o-mini\")\n",
    "# system prompt for the user agent\n",
    "print(f\"system prompt:\\n{user_agent.build_system_prompt('Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"user prompt\" for the User LLM is \"Hi! How can I help you today?\"\n",
    "This way, the User LLM generates a natural language question to address the \"User instruction\" in the above system prompt. \n",
    "\n",
    "Note that you can't modify the system prompt and the user prompt of the User LLM. Also, the User LLM should only be ran by GPT-4o-mini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The sample validation dataset is in the `src/envs/mimic_iv/valid_data.json`. It contains 10 samples for this task. The `src/envs/mimic_iv/test_data.json` contains the same information as in the validation dataset, but with gold SQL and gold answer field removed.\n",
    "\n",
    "IMPORTANT: When created your own custom validation set, make sure that the name of the JSON file is `src/envs/mimic_iv/valid_data.json`. Plus, when given test data, it should be exactly stored in `src/envs/mimic_iv/test_data.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'task_id': '0', 'instruction': 'Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.', 'gold_sql': 'SELECT gender FROM patients WHERE subject_id = 10027602', 'gold_answer': [['f']]}, {'task_id': '1', 'instruction': 'Your goal is to find all the routes of administration for isosorbide dinitrate for patients in the database.', 'gold_sql': \"SELECT DISTINCT prescriptions.route FROM prescriptions WHERE prescriptions.drug = 'isosorbide dinitrate'\", 'gold_answer': [['po/ng']]}]\n",
      "[{'task_id': '0', 'instruction': 'Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.'}, {'task_id': '1', 'instruction': 'Your goal is to find all the routes of administration for isosorbide dinitrate for patients in the database.'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"src/envs/mimic_iv/valid_data.json\", 'r') as f:\n",
    "    valid_data = json.load(f)\n",
    "with open(\"src/envs/mimic_iv/test_data.json\", 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(valid_data[:2])\n",
    "print(test_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the formatted version of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task(task_id='0', instruction='Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.', gold_sql='SELECT gender FROM patients WHERE subject_id = 10027602', gold_answer=[['f']]), Task(task_id='1', instruction='Your goal is to find all the routes of administration for isosorbide dinitrate for patients in the database.', gold_sql=\"SELECT DISTINCT prescriptions.route FROM prescriptions WHERE prescriptions.drug = 'isosorbide dinitrate'\", gold_answer=[['po/ng']])]\n",
      "[Task(task_id='0', instruction='Your goal is to find the gender of a patient. Specifically, you want to know the gender of the patient with ID 10027602.', gold_sql=None, gold_answer=None), Task(task_id='1', instruction='Your goal is to find all the routes of administration for isosorbide dinitrate for patients in the database.', gold_sql=None, gold_answer=None)]\n"
     ]
    }
   ],
   "source": [
    "from src.types import Task\n",
    "valid_tasks = [Task(**task) for task in valid_data]\n",
    "print(valid_tasks[:2])\n",
    "test_tasks = [Task(**task) for task in test_data]\n",
    "print(test_tasks[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline DB Agent - Tool-calling\n",
    "Now, we will take a look into the tool-calling agent. It uses the following 4 tools:\n",
    "- `sql_db_list_tables`: Get the list of table names in the database.\n",
    "- `sql_db_schema`: Get the columns of a specific table and its sample rows.\n",
    "- `value_substring_search`: Retrieve up to k values from a specific column that contains the specified substring.\n",
    "- `sql_db_query`: Execute a SQL query against the database and get back the result. If the query is not correct, an error message will be returned. The maximum number of results to return is 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at the system prompt of the baseline agent. It contains \"domain policies\" i.e., rules that the DB agent should follow in the MIMIC_IV database. You can see the rules in the \"Rules\" section of the system prompt. We don't recommend changing the domain policies, but you can freely change the system prompt above the \"Rules\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system prompt:\n",
      "- You are a SQL agent that translates natural language questions into precise SQL queries for electronic health records (EHR).\n",
      "- You are currently engaged in a conversation with a user who wants to retrieve data from an EHR database.\n",
      "- If the user's request is ambiguous or missing crucial information (e.g., filtering criteria), you must ask clarifying questions in plain language.\n",
      "- You can interact with the database to learn more about its schema or the values stored in it by using the tools provided.\n",
      "- Do not invent or fabricate any information not provided by the user or the tools.\n",
      "- You should make at most one tool call at a time.\n",
      "- If you do call a tool, do not respond to the user in that same turn.\n",
      "- Do not generate SQL queries directly without knowing the database schema and values intended to be used in the SQL query by calling substring_search_tool.\n",
      "- When the user asks for specific diagnoses, procedures, medications, or lab tests, try your best to use the tool to search for relevant information in the database and determine if it relates to the user's request.\n",
      "- Only when you have gathered all necessary information from the user or the database, produce a single, valid SQL query that fully reflects the user's request.\n",
      "- Avoid partial or speculative queries that could cause confusion or yield inaccurate results.\n",
      "- Your performance is evaluated based on the latest SQL query you generate, so when generating a new SQL query for the user's request, avoid relying on previous results but instead rewrite it from scratch to fully capture the user's intent and ensure it is accurately assessed.\n",
      "\n",
      "Rules:\n",
      "- Task:\n",
      "  - The DB agent is required to use SQL at least once to retrieve answers during the conversation, as all questions pertain to patient records in the database.\n",
      "  - When searching for specific values stored in the database (e.g., diagnosis names or drug names), retrieve all relevant items, then narrow down to what the user specifically wants. The user does not know the exact form of the values stored in the database.\n",
      "  - When presenting answers to the user based on SQL output, use the exact forms from the SQL output verbatim (e.g., recorded timestamps, medication names, or diagnosis names).\n",
      "  - For calculations that may result in decimal points (e.g., number of days or hours), present the result rounded to three decimal places.\n",
      "  - The performance of the DB agent is evaluated based only on the latest SQL query generated. When creating a new SQL query for an updated user's request, rewrite it from scratch to fully capture the user's latest intent in a single SQL query.\n",
      "  - Sometimes, there may be a request that cannot be fulfilled by the DB agent (e.g., the user's request is beyond SQL tasks or no results are found). In that case, the DB agent must state which part of the request you cannot fulfill and ask the user to provide further clarification or try a different request.\n",
      "  - Do not transfer the task to a human; human interaction is only allowed for gathering extra information you need to solve the user's request.\n",
      "- SQL generation:\n",
      "  - Use SQLite for SQL query generation.\n",
      "  - The current time is '2100-12-31 23:59:00'. When referring to time, do not use SQLite's native functions like now. Instead, use '2100-12-31 23:59:00' for 'now', '2100-12-31' for 'today', '2100-12' for 'this month', and '2100' for 'this year'.\n",
      "  - Use DENSE_RANK() when asked for ranking results, but retrieve only the relevant items, excluding their counts or ranks. When the question does not explicitly mention ranking, do not use DENSE_RANK().\n",
      "  - Use DISTINCT in queries related to the cost of events, drug routes, or when counting or listing patients or hospital/ICU visits.\n",
      "  - When calculating the total cost, sum the patientâ€™s diagnoses, procedures, lab events, and prescription costs within a single hospital admission only.\n",
      "  - Use DISTINCT to retrieve the cost of a single event (diagnosis, procedure, lab event, or prescription).\n",
      "  - For cost-related questions, use cost.event_type to specify the event type ('procedures_icd', 'labevents', 'prescriptions', 'diagnoses_icd') when retrieving costs for procedures, lab events, prescriptions, or diagnoses, respectively.\n",
      "  - Calculate a patient's age once per hospital admission. The age remains constant even if the hospital stay exceeds one year.\n",
      "  - Use inputevents for input-related values and outputevents for output-related values.\n",
      "  - When asked about the careunit, refer to the careunit information in the transfer table.\n",
      "  - When asked to retrieve procedures, diagnoses, or lab tests, return their names or labels of their medical codes (i.e., procedure: d_icd_procedures.long_title, diagnosis: d_icd_diagnoses.long_title, lab test: d_labitems.label).\n",
      "  - When a question involves the time of diagnosis in relation to other types of events, use the first diagnosis time for each patient.\n"
     ]
    }
   ],
   "source": [
    "from src.agents.tool_calling_agent import ToolCallingAgent\n",
    "with open(\"src/envs/mimic_iv/rules.txt\", 'r') as f:\n",
    "    db_agent_rules = f.read()\n",
    "# dummy tool-calling agent\n",
    "tc_agent = ToolCallingAgent(tools_info=[], rule=db_agent_rules, model=\"gpt-4o-mini\")\n",
    "# system prompt for the tool-calling agent\n",
    "print(f\"system prompt:\\n{tc_agent.instruction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the tools the DB Agent uses. It can be found in the `src/envs/mimic_iv/tools/` folder. When implementing your own tools, we recommend to create the necessary files in the same folder as this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_db_list_tables:\n",
      "{'type': 'function', 'function': {'name': 'sql_db_list_tables', 'description': 'Get the list of table names in the database.', 'parameters': {'type': 'object', 'properties': {'tool_input': {'type': 'string', 'description': 'An empty string; no input required.'}}, 'required': []}}}\n",
      "sql_db_schema:\n",
      "{'type': 'function', 'function': {'name': 'sql_db_schema', 'description': 'Get the columns of a specific table and its sample rows.', 'parameters': {'type': 'object', 'properties': {'table_names': {'type': 'string', 'description': 'A comma-separated list of table names to retrieve schema and sample rows for.'}}, 'required': ['table_names']}}}\n",
      "value_substring_search:\n",
      "{'type': 'function', 'function': {'name': 'substring_search_tool', 'description': 'Retrieve up to k values from a column that contains the specified substring.', 'parameters': {'type': 'object', 'properties': {'table': {'type': 'string', 'description': 'The table name.'}, 'column': {'type': 'string', 'description': 'The column name.'}, 'value': {'type': 'string', 'description': 'The substring to search for.'}, 'k': {'type': 'integer', 'description': 'The maximum number of values to return. Default is 100.'}}, 'required': ['table', 'column', 'value']}}}\n",
      "sql_db_query:\n",
      "{'type': 'function', 'function': {'name': 'sql_db_query', 'description': 'Execute a SQL query against the database and get back the result. If the query is not correct, an error message will be returned. The maximum number of results to return is 100.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'A valid SQL query to execute.'}, 'k': {'type': 'integer', 'description': 'The maximum number of results to return. Default is 100.'}}, 'required': ['query']}}}\n"
     ]
    }
   ],
   "source": [
    "from src.envs.mimic_iv.tools.sql_db_list_tables import SqlDbListTables\n",
    "from src.envs.mimic_iv.tools.sql_db_schema import SqlDbSchema\n",
    "from src.envs.mimic_iv.tools.value_substring_search import ValueSubstringSearch\n",
    "from src.envs.mimic_iv.tools.sql_db_query import SqlDbQuery\n",
    "\n",
    "print(f\"sql_db_list_tables:\\n{SqlDbListTables.get_info()}\")\n",
    "print(f\"sql_db_schema:\\n{SqlDbSchema.get_info()}\")\n",
    "print(f\"value_substring_search:\\n{ValueSubstringSearch.get_info()}\")\n",
    "print(f\"sql_db_query:\\n{SqlDbQuery.get_info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By feeding this to the `tools_info` in the DB Agent, the agent decides when or when not to use the tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference & Evaluation\n",
    "\n",
    "Now, let's see how the User LLM and the DB agent interacts.\n",
    "\n",
    "`run.py` simulates the conversation between the User LLM and the DB Agent. However, you should feed necessary information when running your own DB agent:\n",
    "- model: The backbone model of the DB Agent\n",
    "- agent_strategy: the name of your DB agent. See `src/agent_factory.py` for details. When implemented your own DB agent, you should fill in the TODO: field.\n",
    "- max_concurrency: the number of concurrent samples to run at once. Larger number leads to faster inference.\n",
    "- eval_mode: \"valid\" or \"test\". When running inference on valid_data.json, where you have the gold SQL and the gold answer, it should be \"valid\". On the other hand, when running inference on test_data.json, where you don't have the gold SQL and the gold answer, it should be \"test\". When running on the test set, no evaluation (i.e., outputting final scores) is done. However, you can still see the inference results.\n",
    "\n",
    "\n",
    "Check `run_mimic_iv.sh` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the shell script `run_mimic_iv.sh`. This might take a while.\n",
    "! bash run_mimic_iv.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the inference is done, the results (conversation trajectories between the User LLM and the DB Agent) are saved in the `results/` folder. The name of the result file contains meta information about the inference. You should change the name of the file to `team_{team_number}.json` e.g., `team_1.json` and upload it to KLMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: $0.19\n"
     ]
    }
   ],
   "source": [
    "# checking the total cost of the inference\n",
    "import json\n",
    "import pandas as pd\n",
    "path = 'results/mimic_iv-tool-calling-gpt-4o-mini-0.0_range_0--1_user-gpt-4o-mini-llm_0421105745_valid.json'\n",
    "with open(path, 'r') as f:\n",
    "    results = json.load(f)\n",
    "print(f'Total cost: ${round(sum([l[\"cost\"][\"total_cost\"] for l in results if pd.notna(l[\"cost\"][\"total_cost\"])]), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you need to do:\n",
    "1. Implement your own agent in `src/agents/` (`TODO_implement_agent.py`)\n",
    "2. If needed, implement the tools your agent will use in `src/envs/mimic_iv/tools/` (`TODO_implement_tool.py`)\n",
    "3. Change `src/envs/mimic_iv/env.py` to update the tools the DB agent can use in the environment.\n",
    "4. Change `src/agent_factory.py` to make it able to call your implemented agent.\n",
    "5. Change `run_mimic_iv.sh` to do inference & evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8505\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.10:8505\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://59.29.246.30:8505\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# viewing conversation trajectories\n",
    "! streamlit run visualizer.py --server.port 8505"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
